{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1610051422131",
   "display_name": "Python 3.9.1 64-bit ('dm2pVenv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lib.mySqlManager as mySqlManager\n",
    "\n",
    "# from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# import sic-learn modules/ ml algoriths\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "# classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# visualization\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, HTML\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# test imports\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataframe from datasets directory\n",
    "# cancer_df = pd.read_csv(\"/src/datasets/breast_cancer_data.csv\")\n",
    "# prtin dataset shape,head and tail in order to understand data structure\n",
    "# print(\"Shape of breast_cancer data:\", cancer_df.shape)\n",
    "# display(cancer_df.head())\n",
    "# display(cancer_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up mySQL database helper.\n",
    "# myhost = 'mysql'\n",
    "\n",
    "# def setUpMySql(engine):\n",
    "#     myDB = \"breastcancer\"\n",
    "#     engine.execute(\"CREATE DATABASE IF NOT EXISTS {};\".format(myDB)) #create db\n",
    "#     # read dataframe from datasets directory\n",
    "#     cancer_df = pd.read_csv(\"/src/datasets/breast_cancer_data.csv\")\n",
    "#     updloadTableFromDF(cancer_df,\"breastdataset\",False)\n",
    "#     print(\"Done\")\n",
    "\n",
    "# def updloadTableFromDF(df,table_name, index=True):\n",
    "#     con_str = 'mysql+pymysql://root:root@{0}:3306/{1}'.format(myhost, \"breastcancer\")\n",
    "#     engine = create_engine(con_str)\n",
    "#     df.to_sql(name = table_name, con = engine, if_exists = 'replace',index=index)\n",
    "#     print(\"Done\")\n",
    "\n",
    "# def fetchBreastData():\n",
    "#     con_str = 'mysql+pymysql://root:root@{0}:3306/{1}'.format(myhost, \"breastcancer\")\n",
    "#     con = create_engine(con_str)\n",
    "#     df = pd.read_sql(\"SELECT * FROM breastcancer.breastdataset\", con=con)\n",
    "#     return df\n",
    "\n",
    "# print(\"Im mySQL manager\")\n",
    "# con_str = 'mysql+pymysql://root:root@{0}:3306'.format(myhost)\n",
    "# engine = create_engine(con_str)\n",
    "# # set up mySQL\n",
    "# mySqlManager.setUpMySql(engine)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read dataframe from MYSQL DB  \n",
    "cancer_df = mySqlManager.fetchBreastData()\n",
    "# prtin dataset shape,head and tail in order to understand data structure\n",
    "print(\"Shape of breast_cancer data:\", cancer_df.shape)\n",
    "display(cancer_df.head())\n",
    "display(cancer_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#apo ta parapano paratiroume oti to dataset apotelite apo 569 sumples opou to kathe ena apo auta     analiete se 33 columns.\n",
    "#Analisi ton columns \n",
    "#1) to column id periexei to id tou digmatos\n",
    "#2) to column diagnosis periexei tin etiketa tou digmatos (label) diladi tin pliroforia pou\n",
    "#epithimoume na provlepsoume sindiazontas tin pliroforia pou eksagoume apo ta ipolipa \n",
    "#xaraktiristika\n",
    "#3) to feature Unnamed:32 to opoio fenete na periexei pola NaN values \n",
    "#4) ta ipolipa 30 xaraktiristika ta opoia voithoun sto na prosdiorisoume to label twn samples.\n",
    "\n",
    "#%% Pie chart\n",
    "labels = 'Benign','Malignant'\n",
    "sizes = (cancer_df['diagnosis'].value_counts(normalize=True) * 100).to_numpy()\n",
    "explode = (0.2, 0) # leei poso tha apexri to kathe komati tis pitas apo ta alla an einai 0 einai enomena me ta alla\n",
    "plt.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "        shadow=True, startangle=90)\n",
    "plt.title('Percentage Of Diagnosis Variable Occurencies')\n",
    "plt.show()\n",
    "\n",
    "#  horizontal bar charts\n",
    "\n",
    "M = cancer_df[(cancer_df['diagnosis'] != 'B')]\n",
    "B = cancer_df[(cancer_df['diagnosis'] == 'B')]\n",
    "\n",
    "y_pos = np.arange(2)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(y_pos, [len(M), len(B)], align='center')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(['malignant', 'benign'])\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_title('Diagnosis Variable Occurencies')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " check dataset for missing values\n",
    " 1) create a new df containing only boolean values representing whether the value is NaN or not (true or false)\n",
    " 2) create the not null df whitch contains the number of not null values per feature\n",
    " 3) display this df in a bar graph.\n",
    "\"\"\"\n",
    "isNullDf = cancer_df.isnull()\n",
    "isNotNullDf = pd.DataFrame(isNullDf.shape[0] - isNullDf.sum(), columns = ['Count'])\n",
    "# create a bar plot for null values\n",
    "plt.figure(figsize=(15, 8))  # width:20, height:3\n",
    "plt.bar(isNotNullDf.index, isNotNullDf['Count'], color ='green', align='edge', width=0.5)\n",
    "# sets x axis labels and spacifies rotation to vertical\n",
    "plt.xticks(isNotNullDf.index, isNotNullDf.index, rotation='vertical')\n",
    "plt.xlabel(\"Feature Name\") \n",
    "plt.ylabel(\"No. of not null values\") \n",
    "plt.title(\"Not Null Values Per Feature\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Notes:\n",
    " from the graph of step 3 we can see that we have no missing values in all featues except from Unamed:32\n",
    " where all values on this column are missing.\n",
    " \n",
    " besids that id column doesn't give us any information \n",
    "\n",
    " So we are dropping from the cancer_df the Unamed:32 and the id columns and store it to a new df named cancerData.\n",
    "\n",
    " episis alazoume tis times tis stilis diagnosis me 0 kai 1\n",
    "\"\"\"\n",
    "\n",
    "cancerData = cancer_df.drop(['id', 'Unnamed: 32'], axis = 1)\n",
    "\n",
    "cancerData['diagnosis'].replace(\"M\", 1, inplace=True)\n",
    "cancerData['diagnosis'].replace(\"B\", 0, inplace=True)\n",
    "\n",
    "display(cancerData.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featur Analysis!\n",
    "\n",
    "# extract information from the cleaned dataset\n",
    "# 1) display a dataframe whitch discribes cancerData characteristics like (count, mean, std etc)\n",
    "# 2) display pandas ploting scatter matrix whitch displays a matrinx consists of graphs for the corellations tha have featurs with each other \n",
    "# and the distribution for each feature on its diagonal\n",
    "display(cancerData.describe())\n",
    "\n",
    "# provaloume ena cluster correlation diagram to opoio mas provalei tin sisxetisi pou exoun ta xaraktiristika metaksi\n",
    "# tous kai mas dixnei kai apotelesma pou prokiptei an efarmosoume ierarxiko algorithmo omadopoiisis pano stin \n",
    "# sisxetisi twn xaraktiristikon.\n",
    "corrMatrix = cancerData.corr()\n",
    "display(corrMatrix.head())\n",
    "plt.figure(figsize =(30,20))\n",
    "sns.clustermap(corrMatrix, annot = False,  fmt = \".2f\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Apo to parapano diagrama paratiroume oti iparxei poli megalos ogkos pliroforias opote gia na na mporesoume\n",
    "na katalavoume kalitera tis sisxetisis tha efarmosoume tin idia diadikasia me ena threshold 0.7 \n",
    "opote kratame ta features pou exoun sisxetisi kata apoliti timi megaliteri tou 0.7 me to xaraktiristiko tis\n",
    "diagnosis\n",
    "\"\"\"\n",
    "threshold = 0.7\n",
    "\n",
    "corr_diagnosis = corrMatrix[abs(corrMatrix.diagnosis) > threshold]\n",
    "corr_diagnosis = corr_diagnosis[corr_diagnosis.index]\n",
    "display(corr_diagnosis)\n",
    "\n",
    "# kai provaloume ena pair plot to opoio einai ena matrix pou dixnei tin grafiki parastasi sisxetisis pou exoun ta \n",
    "# xaraktiristika metaksi tous kai stin diagonio tou perixei\n",
    "plt.figure(figsize =(20,20))\n",
    "sns.pairplot(cancerData[corr_diagnosis.index],  markers = \"x\", hue = \"diagnosis\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    eproepeksergasia dedomenon gia tin efarmogi PCA.\n",
    "    1) aferoume apo to cancer data tin stili diagnosis kai tin apothikeuoume se ena ksexoristo array (label)\n",
    "    2) dimiourgoume ena kenourio dataframe to opoio periexei kanonikopoiimena ta xaraktiristika mas\n",
    "    3) alazoume to onoma ton xaraktiristikon dioti ta xaraktiristika pou tha prokipsoun apo ton PCA (components)\n",
    "    periexoun plirofora apo ola ta xaraktiristika\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# step 1\n",
    "label = cancerData.diagnosis.to_numpy()\n",
    "print(label)\n",
    "\n",
    "x = cancerData.drop(['diagnosis'], axis = 1)\n",
    "\n",
    "# step 2\n",
    "x = StandardScaler().fit_transform(x)  # normalizing the features\n",
    "print(\"\\nShape of normalized data:\", x.shape)\n",
    "\n",
    "# elenxoume an to kanonikopoiimeno mas data set exei mean 0 kai tipiki apoklisi 1\n",
    "print(\"\\nPrints mean:\", np.mean(x), \" and Standard deviation of normalized dataset: \", np.std(x))\n",
    "\n",
    "# step 3: change feature name\n",
    "feature_columns = ['feature' + str(i) for i in range(x.shape[1])]\n",
    "normalized_dataFrame = pd.DataFrame(x, columns=feature_columns)\n",
    "\n",
    "display(normalized_dataFrame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Apply PCA \n",
    "    χρισιμοποιουμε αυτη την μεθοδο για να εφαρμοσουμε τον αλγοριθμο PCA σε ενα κανονικοποιιμενο data set\n",
    "    και επιστρεφουμε ως αποτελεσμα ενα dataFrame με τα δεδομενα που προκυπτουν απο την εφαρμογη του PCA \n",
    "    θεωροντας ως default παραμετρους οτι ο PCA θα μιοσει της διαστασης των δεδομενον στης 2 και το dataFrame\n",
    "    θα εχει column labels τα παρακατο: 'principal component 1', 'principal component 2'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def applyPCA(normalizedData, dimensions=2, dataframeLabels=['principal component 1', 'principal component 2']):\n",
    "    pca = PCA(n_components=dimensions)\n",
    "    pca_data = pca.fit_transform(normalizedData)\n",
    "\n",
    "    print(\"Explained variation per principal component:\", format(pca.explained_variance_ratio_))\n",
    "    print(\"Total variation: \", sum(pca.explained_variance_ratio_))\n",
    "\n",
    "    pca_data_dataFrame = pd.DataFrame(data=pca_data, columns=dataframeLabels)\n",
    "    return pca_data_dataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    USING PCA Gia na provaloume tis 30 diastasis tou dataset se 2 kai 3\n",
    "    gia na pragmatopoiithei auto tha xrisimopoiisoume to paketo PCA tis vivliothikis sklearn\n",
    "    kai stin methodo PCA tha perasoume os argument to plithos ton diastaseon pou theloume na provaloume ta data mas\n",
    "    stin periptosi mas 2 kai 3. Telos tha xrisimopoiisoume tin fit transform gia tin efarmogi tou PCA sta \n",
    "    kanonikopoiimena dedomena pou ipologisame sto proigoumeno bhma (x oxi to normalized_dataFrame pou dimiourgisame gia \n",
    "    visualization purposes.\n",
    "\"\"\"\n",
    "\n",
    "# efarmofi PCA gia 2 diastasis\n",
    "pca_data_dataFrame = applyPCA(x)\n",
    "\n",
    "# lets print the head of our pca data set for testing purposes\n",
    "print(\"-------------- PRINT PCA DATA SET HEAD -------------------\")\n",
    "# print(tabulate(pca_data_dataFrame.head(), headers='keys', tablefmt='psql'))\n",
    "display(pca_data_dataFrame.head())\n",
    "\n",
    "\n",
    "# efarmogi PCA gia 3 diastasis\n",
    "print(\"\\napply PCA to reduce 30 to 3 dimensions\")\n",
    "pca_data_3D_dataFrame = applyPCA(x, dimensions=3, dataframeLabels=['principal component 1', 'principal component 2',\n",
    "                                                                       'principal component 3'])\n",
    "# lets print the head of our pca data set for testing purposes\n",
    "print(\"\\n-------------- PRINT PCA DATA SET HEAD -------------------\")\n",
    "# print(tabulate(pca_data_3D_dataFrame.head(), headers='keys', tablefmt='psql'))\n",
    "display(pca_data_3D_dataFrame.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "  προβαλουμε την αναπαρασταση των δεδομενον που πορεκιψαν απο την εφαρμογη του PCA στο αρχικο data set  \n",
    "\"\"\"\n",
    "\n",
    "# plot 2D pca results\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Principal Component - 1', fontsize=20)\n",
    "plt.ylabel('Principal Component - 2', fontsize=20)\n",
    "plt.title(\"Principal Component Analysis of Breast Cancer Dataset\", fontsize=20)\n",
    "targets = cancerData['diagnosis'].unique()\n",
    "colors = ['r', 'g']\n",
    "for target, color in zip(targets, colors):\n",
    "    indicesToKeep = cancerData['diagnosis'] == target\n",
    "    plt.scatter(pca_data_dataFrame.loc[indicesToKeep, 'principal component 1'],\n",
    "                pca_data_dataFrame.loc[indicesToKeep, 'principal component 2'], c=color, s=50)\n",
    "\n",
    "plt.legend(cancer_df.diagnosis.unique(), prop={'size': 15})\n",
    "plt.show()\n",
    "\n",
    "# plot 3D PCA results\n",
    "plt.figure(figsize=(10, 7))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.set_xlabel('principal component 1')\n",
    "ax.set_ylabel('principal component 2')\n",
    "ax.set_zlabel('principal component 3')\n",
    "targets = cancerData['diagnosis'].unique()\n",
    "colors = ['r', 'g']\n",
    "\n",
    "# Creating plot\n",
    "for target, color in zip(targets, colors):\n",
    "    indicesToKeep = cancerData['diagnosis'] == target\n",
    "\n",
    "    ax.scatter3D(pca_data_3D_dataFrame.loc[indicesToKeep, 'principal component 1'],\n",
    "                    pca_data_3D_dataFrame.loc[indicesToKeep, 'principal component 2'],\n",
    "                    pca_data_3D_dataFrame.loc[indicesToKeep, 'principal component 3'], color=color)\n",
    "\n",
    "plt.title(\"simple 3D PCA results\")\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFoldCV(df, label, classifiers):\n",
    "    \"\"\"\n",
    "    Orizoume mia helper function gia na pragmatopoiei k-fold cross validation\n",
    " \n",
    "    :param df: the x dataset of cross validation\n",
    "    :param label: the y dataset of cross validation\n",
    "    :param classifiers: is a dictionary of classifiers in the folowung format\n",
    "     {\n",
    "        \"name\": \"KNN\",\n",
    "        \"classifier\": KNeighborsClassifier(),\n",
    "        \"train_scores\": [],\n",
    "        \"acc_scores\": []\n",
    "    }\n",
    "    :return: returns the trained classifiers dict\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=10, random_state=None) \n",
    "\n",
    "    for train_index, test_index in kf.split(df):\n",
    "        X_train, X_test = df.loc[train_index, :], df.loc[test_index, :]\n",
    "        y_train, y_test = label[train_index], label[test_index]\n",
    "\n",
    "        # fit train dataset to classifiers\n",
    "        for c in classifiers:\n",
    "            c[\"classifier\"].fit(X_train, y_train)\n",
    "            c[\"train_scores\"].append( c[\"classifier\"].score(X_train, y_train))\n",
    "            c[\"acc_scores\"].append( c[\"classifier\"].score(X_test, y_test))\n",
    "\n",
    "    return classifiers\n",
    "\n",
    "\n",
    "def stratifiedKFoldCV(df, label, classifiers):\n",
    "    \"\"\"\n",
    "    Orizoume mia helper function gia na pragmatopoiei statified k-fold cross validation\n",
    " \n",
    "    :param df: the x dataset of cross validation\n",
    "    :param label: the y dataset of cross validation\n",
    "    :param classifiers: is a dictionary of classifiers in the folowung format\n",
    "     {\n",
    "        \"name\": \"KNN\",\n",
    "        \"classifier\": KNeighborsClassifier(),\n",
    "        \"train_scores\": [],\n",
    "        \"acc_scores\": []\n",
    "    }\n",
    "    :return: returns the trained classifiers dict\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=10, random_state=None)\n",
    "    # pca_data_dataFrame is the feature set and label is the target\n",
    "    for train_index, test_index in skf.split(df,label): \n",
    "        X_train, X_test = df.loc[train_index, :], df.loc[test_index, :]\n",
    "        y_train, y_test = label[train_index], label[test_index]\n",
    "\n",
    "        # fit train dataset to classifiers\n",
    "        for c in classifiers:\n",
    "            c[\"classifier\"].fit(X_train, y_train)\n",
    "            c[\"train_scores\"].append( c[\"classifier\"].score(X_train, y_train))\n",
    "            c[\"acc_scores\"].append( c[\"classifier\"].score(X_test, y_test))\n",
    "    return classifiers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    xorisoume to dataset mas se 2 meroi train kai test sumple.\n",
    "    gia na einai poio antiprosopeftiko to apotelesma tis diadikasias tha xrisimopoiisoume\n",
    "    tin texniki k-fold-cross-validation gia na efarmostei to modelo mas me arketous piithanous \n",
    "    sindiasmous train kai test gia na imaste sigouroi oti ta apotelesmata mas einai antiprosopeutika\n",
    "\"\"\"\n",
    "\n",
    "classifiers = [\n",
    "    {\n",
    "        \"name\": \"KNN\",\n",
    "        \"classifier\": KNeighborsClassifier(),\n",
    "        \"train_scores\": [],\n",
    "        \"acc_scores\": []\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"LogisticRegression\",\n",
    "        \"classifier\": LogisticRegression(),\n",
    "        \"train_scores\": [],\n",
    "        \"acc_scores\": []\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"LinearRegression\",\n",
    "        \"classifier\": LinearRegression(),\n",
    "        \"train_scores\": [],\n",
    "        \"acc_scores\": []\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"DecisionTreeClassifier\",\n",
    "        \"classifier\": DecisionTreeClassifier(),\n",
    "        \"train_scores\": [],\n",
    "        \"acc_scores\": [] \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"GaussianNB\",\n",
    "        \"classifier\": GaussianNB(),\n",
    "        \"train_scores\": [],\n",
    "        \"acc_scores\": [] \n",
    "    }\n",
    "]\n",
    "\n",
    "# this list will contain results in dict format in order to display them into dataframe.\n",
    "results = []\n",
    "\n",
    "display(pca_data_dataFrame)\n",
    "\n",
    "classifier = kFoldCV(pca_data_dataFrame, label, classifiers)\n",
    "\n",
    "# ipologizoume tin mesi timi ton apotelesmaton tou taksinomiti mas pou proekipsan apo tin 10-fold-cross-validation\n",
    "for c in classifiers:\n",
    "    print(\"Results for classifier {}: training score: {:.4f}, Accuracy: {:.4f} using 2 Principal Components and simple kfold \\n\".format(c[\"name\"], np.mean(c[\"train_scores\"]), np.mean(c[\"acc_scores\"])))\n",
    "    results.append({\n",
    "    \"algorithm\": c[\"name\"],\n",
    "    \"test\": \"2D-PCA\",\n",
    "    \"folds\": \"K-Fold\",\n",
    "    \"train_score\": np.mean(c[\"train_scores\"]),\n",
    "    \"test_score\": np.mean(c[\"acc_scores\"])\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Epanalamvanoume tin idia diadikasia gia stratified k-fold cross validation \n",
    "gia ola ta montela provlepsis pou ilopoiisame.\n",
    "\"\"\"\n",
    "\n",
    "# reset classifiers\n",
    "for c in classifiers:\n",
    "    c[\"acc_scores\"] = []\n",
    "    c[\"train_scores\"] = []\n",
    "\n",
    "classifiers = stratifiedKFoldCV(pca_data_dataFrame, label, classifiers)\n",
    "\n",
    "# ipologizoume tin mesi timi ton apotelesmaton tou taksinomiti mas pou proekipsan apo tin 10-fold-cross-validation\n",
    "for c in classifiers:\n",
    "    print(\"Results for classifier {}: training score: {:.4f}, Accuracy: {:.4f} using 2 Principal Components and stratified K-fold \\n\".format(c[\"name\"], np.mean(c[\"train_scores\"]), np.mean(c[\"acc_scores\"])))\n",
    "    results.append({\n",
    "    \"algorithm\": c[\"name\"],\n",
    "    \"test\": \"2D-PCA\",\n",
    "    \"folds\": \"stratified-K-Fold\",\n",
    "    \"train_score\": np.mean(c[\"train_scores\"]),\n",
    "    \"test_score\": np.mean(c[\"acc_scores\"])\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Epanalamvanoume tin parapano diadikasia gia ta 3 principal components tou PCA.\n",
    "\"\"\"\n",
    "\n",
    "# reset classifiers\n",
    "for c in classifiers:\n",
    "    c[\"acc_scores\"] = []\n",
    "    c[\"train_scores\"] = []\n",
    "\n",
    "\n",
    "classifier = kFoldCV(pca_data_3D_dataFrame, label, classifiers)\n",
    "\n",
    "\n",
    "# kf = KFold(n_splits=10, random_state=None) \n",
    "\n",
    "# ipologizoume tin mesi timi ton apotelesmaton tou taksinomiti mas pou proekipsan apo tin 10-fold-cross-validation\n",
    "for c in classifiers:\n",
    "    print(\"Results for classifier {}: training score: {:.4f}, Accuracy: {:.4f} using 3 Principal Components and simple kfold \\n\".format(c[\"name\"], np.mean(c[\"train_scores\"]), np.mean(c[\"acc_scores\"])))\n",
    "    results.append({\n",
    "    \"algorithm\": c[\"name\"],\n",
    "    \"test\": \"3D-PCA\",\n",
    "    \"folds\": \"K-Fold\",\n",
    "    \"train_score\": np.mean(c[\"train_scores\"]),\n",
    "    \"test_score\": np.mean(c[\"acc_scores\"])\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Epanalamvanoume tin idia diadikasia gia stratified k-fold cross validation \n",
    "gia ola ta montela provlepsis pou ilopoiisame.\n",
    "\"\"\"\n",
    "\n",
    "# reset classifiers\n",
    "for c in classifiers:\n",
    "    c[\"acc_scores\"] = []\n",
    "    c[\"train_scores\"] = []\n",
    "\n",
    "classifiers = stratifiedKFoldCV(pca_data_3D_dataFrame, label, classifiers)\n",
    "\n",
    "# ipologizoume tin mesi timi ton apotelesmaton tou taksinomiti mas pou proekipsan apo tin 10-fold-cross-validation\n",
    "for c in classifiers:\n",
    "    print(\"Results for classifier {}: training score: {:.4f}, Accuracy: {:.4f} using 3 Principal Components and stratified K-fold \\n\".format(c[\"name\"], np.mean(c[\"train_scores\"]), np.mean(c[\"acc_scores\"])))\n",
    "    results.append({\n",
    "    \"algorithm\": c[\"name\"],\n",
    "    \"test\": \"3D-PCA\",\n",
    "    \"folds\": \"stratified-K-Fold\",\n",
    "    \"train_score\": np.mean(c[\"train_scores\"]),\n",
    "    \"test_score\": np.mean(c[\"acc_scores\"])\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Epanalamvanoume thn diadikasia gia kratontas ta xaraktiristika pou parousiazoun sisxetisi megaliterei apo 0.7 kata apolith timi\n",
    "1) kratisame ta xaraktiristika pou exoun sisxetisi megaliteri apo 0.7 me to xaraktiristiko stoxos\n",
    "gia na epiteuthei auto xrisimopoiisame to correlation ton xaraktiristikwn pou ipologisame kata tin provoli tou Heatmap kai apomonosame \n",
    "apo to kurio dataset ta features pou oikanopoioun tin sunthiki.\n",
    "2) Stun sinexeia kanonikopoiisame ta dedomena pou diamorfosame proigumenos kai ta dosame ws inpunt ston algorithmo K-fold prokimenou\n",
    "na ipologisoyme to score provlepeis\n",
    "\"\"\"\n",
    "\n",
    "data = cancerData[corr_diagnosis.index]\n",
    "data = data.drop(['diagnosis'], axis=1)\n",
    "\n",
    "# for feature in data.columns:\n",
    "#         le = preprocessing.LabelEncoder()\n",
    "#         data[feature] = le.fit_transform(data[feature])\n",
    "        # x[feature] = le.transform(X_test[feature])\n",
    "\n",
    "data = StandardScaler().fit_transform(data)\n",
    "feature_columns = ['feature' + str(i) for i in range(data.shape[1])]\n",
    "data = pd.DataFrame(data, columns=feature_columns)\n",
    "\n",
    "# reset classifiers\n",
    "for c in classifiers:\n",
    "    c[\"acc_scores\"] = []\n",
    "    c[\"train_scores\"] = []\n",
    "\n",
    "classifiers = kFoldCV(data, label, classifiers)\n",
    "\n",
    "# ipologizoume tin mesi timi ton apotelesmaton tou taksinomiti mas pou proekipsan apo tin 10-fold-cross-validation\n",
    "for c in classifiers:\n",
    "    print(\"Results for classifier {}: training score: {:.4f}, Accuracy: {:.4f} using features with correlation greater than 0.7 with class feature and normal K-fold \\n\".format(c[\"name\"], np.mean(c[\"train_scores\"]), np.mean(c[\"acc_scores\"])))\n",
    "    results.append({\n",
    "    \"algorithm\": c[\"name\"],\n",
    "    \"test\": \"Custom DR\",\n",
    "    \"folds\": \"K-Fold\",\n",
    "    \"train_score\": np.mean(c[\"train_scores\"]),\n",
    "    \"test_score\": np.mean(c[\"acc_scores\"])\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reset classifiers\n",
    "for c in classifiers:\n",
    "    c[\"acc_scores\"] = []\n",
    "    c[\"train_scores\"] = []\n",
    "\n",
    "classifiers = stratifiedKFoldCV(data, label, classifiers)\n",
    "\n",
    "# ipologizoume tin mesi timi ton apotelesmaton tou taksinomiti mas pou proekipsan apo tin 10-fold-cross-validation\n",
    "for c in classifiers:\n",
    "    print(\"Results for classifier {}: training score: {:.4f}, Accuracy: {:.4f} using features with correlation greater than 0.7 with class feature and stratified K-fold \\n\".format(c[\"name\"], np.mean(c[\"train_scores\"]), np.mean(c[\"acc_scores\"])))\n",
    "    results.append({\n",
    "    \"algorithm\": c[\"name\"],\n",
    "    \"test\": \"Custom DR\",\n",
    "    \"folds\": \"stratified-K-Fold\",\n",
    "    \"train_score\": np.mean(c[\"train_scores\"]),\n",
    "    \"test_score\": np.mean(c[\"acc_scores\"])\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folds = [\"K-Fold\", \"Stratified K-Fold\"]\n",
    "tests = [\"2D-PCA\", \"3D-PCA\", \"CUSTOM-DIM-REDUCTION\"]\n",
    "\n",
    "classifiers_df = pd.DataFrame.from_dict(results)\n",
    "\n",
    "classifiers_df = classifiers_df.set_index(['folds', 'test', \"algorithm\"]) \n",
    "# classifiers_df = classifiers_df.set_index('test') \n",
    "\n",
    "# classifiers_df = classifiers_df.set_index(folds)\n",
    "display(classifiers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reset indexies\n",
    "classifiers_df.reset_index(drop=False, inplace=True)\n",
    "display(classifiers_df)\n",
    "# UPLOAD CLASSIFICATION RESULTS TO MYSQL\n",
    "mySqlManager.updloadTableFromDF(classifiers_df, \"classifiers_results\")\n"
   ]
  }
 ]
}